# -*- coding: utf-8 -*-
"""GNR638_project1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1apYnuP2px0bmuQAgOkagcGUKX75WoU9j
"""

from IPython.display import Image
import os
import pandas as pd
from io import StringIO
import sys

log_file_path = '/content/training_logs.txt'  # Change the path as needed

log_file = open(log_file_path, 'w')

# Redirect stdout to the log file
sys.stdout = log_file

with open('/content/drive/MyDrive/CUB_200_2011/images.txt', 'r') as f:
  images_text = f.read()

with open('/content/drive/MyDrive/CUB_200_2011/train_test_split.txt', 'r') as f:
  train_test = f.read()

with open('/content/drive/MyDrive/CUB_200_2011/image_class_labels.txt', 'r') as f:
  labels_text = f.read()

data_labels=pd.read_csv(StringIO(labels_text), sep=' ', header=None, names=['Number', 'Data'])
data_images=pd.read_csv(StringIO(images_text), sep=' ', header=None, names=['Number', 'Data'])
data_split=pd.read_csv(StringIO(train_test), sep=' ', header=None, names=['Number', 'Data'])

data_labels_column=data_labels['Data']
data_images_column=data_images['Data']
data_split_column=data_split['Data']

df=pd.DataFrame({
    'images':data_images_column,
    'labels': data_labels_column-1,
    'is_train': data_split_column
})

df

dir_path='/content/drive/MyDrive/CUB_200_2011/images/'

# images_path = '/content/drive/MyDrive/CUB_200_2011/images/005.Crested_Auklet/Crested_Auklet_0001_794941.jpg'

image_path=os.path.join(dir_path, df['images'][568])

Image(filename=image_path)

df_train = df[df['is_train']==1]
df_test = df[df['is_train']==0]

df_train

for index, row in df_train.iterrows():
  print(f"index: {index} row: {row['images']}")

import torch
from torchvision import transforms
from torch.utils.data import Dataset, DataLoader
from PIL import Image
import os

class CustomImageDataset(Dataset):
    def __init__(self, data_list, transform=None):
        self.data_list = data_list
        self.transform = transform

    def __len__(self):
        return len(self.data_list)

    def __getitem__(self, idx):
        img_path, label = self.data_list[idx]
        image = Image.open(img_path).convert('RGB')

        if self.transform:
            image = self.transform(image)

        return image, label

train_data_list = []

for index, row in df_train.iterrows():
    # Assuming 'images' column contains the relative paths
    image_path = os.path.join(dir_path, row['images'])
    label = row['labels']
    train_data_list.append((image_path, label))

test_data_list = []

for index, row in df_test.iterrows():
    # Assuming 'images' column contains the relative paths
    image_path = os.path.join(dir_path, row['images'])
    label = row['labels']
    test_data_list.append((image_path, label))

# Define your transformations for training and testing
train_transform = transforms.Compose([
    transforms.RandomResizedCrop(224),
    transforms.RandomHorizontalFlip(),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
])

test_transform = transforms.Compose([
    transforms.Resize(256),
    transforms.CenterCrop(224),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
])

# Create datasets using CustomImageDataset
train_dataset = CustomImageDataset(data_list=train_data_list, transform=train_transform)
test_dataset = CustomImageDataset(data_list=test_data_list, transform=test_transform)

# Create DataLoader for training and testing
batch_size = 64
train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)
test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)

# for batch_idx, (data, targets) in enumerate(train_dataloader):
#     print(f"Batch {batch_idx + 1} - Data Shape: {data.shape}, Targets Shape: {targets.shape}")
#     # Additional analysis or visualization if needed

# import matplotlib.pyplot as plt

# # Assuming single-channel images (grayscale)
# for inputs, labels in train_dataloader:
#     plt.hist(labels.numpy(), bins=len(train_dataloader.dataset.classes))
#     plt.title('Class Distribution')
#     plt.xlabel('Class')
#     plt.ylabel('Count')
#     plt.show()
#     break  # Only analyze the first batch for simplicity

# import matplotlib.pyplot as plt
# import torchvision.utils as vutils

# for inputs, labels in train_dataloader:
#     # Create a grid of images
#     img_grid = vutils.make_grid(inputs, nrow=8, normalize=True)
#     # Display the images
#     plt.imshow(img_grid.permute(1, 2, 0))
#     plt.axis('off')
#     plt.show()
#     break  # Only visualize the first batch for simplicity

import torch
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
from torch import nn
device

import torchvision
import torch.optim as optim
import torch.nn.functional as F

# import torchvision.datasets as datasets
import torchvision.transforms as transforms
from tqdm import tqdm

# Hyperparameters
num_classes = 200
learning_rate = 1e-3
batch_size = 64
num_epochs = 5

from torchvision import models

model_ft = models.resnet18(weights='IMAGENET1K_V1')
num_ftrs = model_ft.fc.in_features
# Here the size of each output sample is set to 2.

for param in model_ft.parameters():
    param.requires_grad = False
# Alternatively, it can be generalized to ``nn.Linear(num_ftrs, len(class_names))``.
model_ft.fc = nn.Linear(num_ftrs, num_classes)
# Add Softmax activation
# model_ft.softmax = nn.Softmax(dim=1)

model_ft = model_ft.to(device)

from torchsummary import summary
summary(model_ft, (3, 224, 224), device="cuda" if torch.cuda.is_available() else "cpu")

# !pip install torchmetrics

# from torchmetrics import CrossEntropyLoss
# criterion = CrossEntropyLoss(num_classes=num_classes)

criterion = nn.CrossEntropyLoss()
criterion = criterion.to(device)

# Set the model to training mode
model_ft.train()
# Observe that all parameters are being optimized
optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)

# Train Network
for epoch in range(num_epochs):
    losses = []

    for batch_idx, (data, targets) in enumerate(tqdm(train_dataloader)):
        # Get data to cuda if possible
        data = data.to(device=device)
        targets = targets.to(device=device)
        # forward
        scores = model_ft(data)
        print(f"Score shape: {scores.shape}")
        print(f"targets shape: {targets.shape}")

        loss = criterion(scores, targets)

        losses.append(loss.item())
        # backward
        optimizer_ft.zero_grad()
        loss.backward()

        # gradient descent or adam step
        optimizer_ft.step()

    print(f"Cost at epoch {epoch} is {sum(losses)/len(losses):.5f}")

# Check accuracy on training & test to see how good our model


def check_accuracy(loader, model):
    # if loader.dataset.train:
    #     print("Checking accuracy on training data")
    # else:
    #     print("Checking accuracy on test data")

    num_correct = 0
    num_samples = 0
    model.eval()

    with torch.no_grad():
        for x, y in loader:
            x = x.to(device=device)
            y = y.to(device=device)

            scores = model(x)
            _, predictions = scores.max(1)
            num_correct += (predictions == y).sum()
            num_samples += predictions.size(0)

        print(
            f"Got {num_correct} / {num_samples} with accuracy {float(num_correct)/float(num_samples)*100:.2f}"
        )

    model.train()


check_accuracy(train_dataloader, model_ft)



log_file.close()

# Restore the original stdout
sys.stdout = sys.__stdout__

"""# Extra Stuff"""

import torch
import torch.nn as nn

class ModifiedVGG16(nn.Module):
    def __init__(self, num_classes=200):
        super(ModifiedVGG16, self).__init__()
        self.features = nn.Sequential(
            nn.Conv2d(3, 64, kernel_size=3, padding=1),
            nn.ReLU(inplace=True),
            nn.Conv2d(64, 64, kernel_size=3, padding=1),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(kernel_size=2, stride=2),

            nn.Conv2d(64, 128, kernel_size=3, padding=1),
            nn.ReLU(inplace=True),
            nn.Conv2d(128, 128, kernel_size=3, padding=1),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(kernel_size=2, stride=2),

            nn.Conv2d(128, 256, kernel_size=3, padding=1),
            nn.ReLU(inplace=True),
            nn.Conv2d(256, 256, kernel_size=3, padding=1),
            nn.ReLU(inplace=True),
            nn.Conv2d(256, 256, kernel_size=3, padding=1),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(kernel_size=2, stride=2),

            nn.Conv2d(256, 512, kernel_size=3, padding=1),
            nn.ReLU(inplace=True),
            # nn.Conv2d(512, 512, kernel_size=3, padding=1),
            # nn.ReLU(inplace=True),
            nn.Conv2d(512, 512, kernel_size=3, padding=1),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(kernel_size=2, stride=2),

            nn.Conv2d(512, 512, kernel_size=3, padding=1),
            nn.ReLU(inplace=True),
            # nn.Conv2d(512, 512, kernel_size=3, padding=1),
            # nn.ReLU(inplace=True),
            nn.Conv2d(512, 512, kernel_size=3, padding=1),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(kernel_size=2, stride=2)
        )
        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))
        self.classifier = nn.Sequential(
            nn.Linear(512, num_classes)
        )

    def forward(self, x):
        x = self.features(x)
        x = self.avgpool(x)
        x = torch.flatten(x, 1)
        x = self.classifier(x)
        return x

# Create an instance of the modified VGG16 model
modified_vgg16_model = ModifiedVGG16(num_classes=200)

modified_vgg16_model.to(device)

from torchsummary import summary
summary(modified_vgg16_model, (3, 224, 224), device="cuda" if torch.cuda.is_available() else "cpu")

criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(modified_vgg16_model.parameters(), lr=learning_rate)

import torch
from torchvision import models
from torch import nn
from torch.utils.data import DataLoader
from torchvision import transforms

# Assuming you have loaded your dataset and created a DataLoader (train_dataloader)

# Define your transformations for training
transform = transforms.Compose([
    transforms.Resize(256),
    transforms.CenterCrop(224),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
])

# Load the pretrained model
model = models.efficientnet_b4(pretrained=True).cuda()

# Replace the classifier
classifier = nn.Sequential(
    nn.Linear(in_features=model.classifier[1].in_features, out_features=256, bias=True),
    nn.ReLU(),
    nn.Linear(in_features=256, out_features=525, bias=True)
)
model.classifier = classifier

# Move the model to GPU
model = model.cuda()

# Define loss function and optimizer
criterion = nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(model.parameters(), lr=0.001)

# Training loop
num_epochs = 5  # Adjust as needed
for epoch in range(num_epochs):
    model.train()  # Set the model to training mode
    running_loss = 0.0
    correct_predictions = 0
    total_samples = 0

    for inputs, labels in train_dataloader:
        inputs, labels = inputs.cuda(), labels.cuda()

        optimizer.zero_grad()
        outputs = model(inputs)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()

        running_loss += loss.item()
        _, predicted = torch.max(outputs, 1)
        correct_predictions += (predicted == labels).sum().item()
        total_samples += labels.size(0)

    epoch_loss = running_loss / len(train_dataloader)
    epoch_accuracy = correct_predictions / total_samples

    print(f'Epoch {epoch + 1}/{num_epochs} - Loss: {epoch_loss:.4f}, Accuracy: {epoch_accuracy:.4f}')

"""# Code form kaggle that might be useful"""

from PIL import Image
import numpy as np
import os


# Function to calculate mean and std for image data
def calculate_mean_std(image_paths, percent):

    image_paths = image_paths.sample(frac=percent, random_state=42)
    # Initialize lists to store channel-wise means and stds
    channel_means = [0.0, 0.0, 0.0]
    channel_stds = [0.0, 0.0, 0.0]
    # Iterate through each image and accumulate pixel values
    for img_path in tqdm(image_paths):
        img = Image.open(img_path)
        img_array = np.array(img) / 255.0  # Normalize pixel values to be in the range [0, 1]

        # Accumulate mean and std for each channel
        for i in range(3):  # Assuming RGB images
            channel_means[i] += np.mean(img_array[:, :, i])
            channel_stds[i] += np.std(img_array[:, :, i])

    # Calculate average mean and std
    num_images = len(image_paths)
    mean = [c_mean / num_images for c_mean in channel_means]
    std = [c_std / num_images for c_std in channel_stds]

    return mean, std

mean, std = calculate_mean_std(data_train['path'], 0.9)
mean, std

import torchvision.transforms as transform
import torchvision
transformer = transform.Compose([
                           transform.Resize((224, 224)),
                           transform.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),
                           transform.RandomRotation(5),
                           transform.RandomAffine(degrees=11, translate=(0.1,0.1), scale=(0.8,0.8)),
                           transform.ToTensor(),
                           transform.Normalize(mean,
                                               std)
])

